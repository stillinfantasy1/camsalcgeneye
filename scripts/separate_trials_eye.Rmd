---
title: "separate_trials_eye.Rmd"
output: html_document
date: "2023-11-12"
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(pacman)
library(PupilPre)
```


# set subject & directories
```{r}
subj <- 'L003'

proj_dir <- '~/Box Sync/CAMSLab_Projects/Studies/AlcGen/Data/In_Lab/'
behav_fname <- paste0(subj, '_processed_conditioning_data.csv')

eye_dir <- paste0(proj_dir, 'eye/raw/', subj, '/', subj, '_conditioning/Output/')
fname <- paste0(subj, '_conditioning.txt')

out_dir <- paste0(proj_dir, 'eye/preprocessed/', subj, '/')
log_dir <- paste0(proj_dir, 'eye/logs')
if (!(dir.exists(out_dir))) {
  dir.create(out_dir)
}

```

# experiment settings
```{r}
phase_name = c("fixation_onset", "cs_onset", "anticipation_onset", "us_onset")

# sampling rate: 1 sample/2 msec (500 sample/sec)
samp_rate = 500
phase_dur = c(3, 2, 3, 2)
phase_dur.adj = phase_dur*samp_rate

baseline_dur = 1
baseline_dur.adj = baseline_dur*samp_rate

```

# preproc function
```{r}
preprocess_eye <- function(subject, task, phase, phase_data, baseline_window, out_dir, log_dir) {
  
  # define paths
  cat(sprintf("Processing subject %s, task %s, phase %s\n", subject, task, phase))
  output_path <- paste0(out_dir, subject, '_', task, '_', phase, '_preprocessed.csv') 

  # Check if the "logs" directory exists, if not, create it
  if (!dir.exists(log_dir)) {
    dir.create(log_dir)
  }
  
  # Construct the paths for the log files
  log_blinks_path <- sprintf("%s/%s_%s_%s_BlinkCleanupLog.rds", log_dir, subject, task, phase)
  log_artifacts_path <- sprintf("%s/%s_%s_%s_ArtifactCleanupLog.rds", log_dir, subject, task, phase)
  
    # Create the time series column for subsequent processing and plotting. Keep in mind: reserve 1s prior to the onset of the cs_onset as a baseline while exporting the sample report from Data Viewer . So, cs_onset starts from Time 0, while the baseline starts from Time -1000
  prep_timeseries <- create_time_series(data = phase_data, Adjust = baseline_window) 

  print('checking time adjustment...')
  print(prep_timeseries$Time)
  
  # Select the right eye for analysis
  ppl_check_eye_recording(data = prep_timeseries)
  prep_reye <- ppl_select_recorded_eye(data = prep_timeseries, Recording = "R", WhenLandR = "Right")
  
  # Check for blinks and missing data, and clean them
  blink_summary(prep_reye, Summary = "Event")
  NA_summary(prep_reye, Summary = "Event", PupilColumn = "Pupil")
  prep_rmblinks <- clean_blink(prep_reye, BlinkPadding = c(100, 100), Delta = 5,
                                MaxValueRun = 5, NAsAroundRun = c(2,2),
                                LogFile = log_blinks_path)
  #plot_compare_app(prep_rmblinks)
  
  # identifies the marked blinks and adds padding around them to create a marked time window within which data may be removed. This padding is given in BlinkPadding specifying the number of milliseconds to pad on either side of the blink.
  # with this window, the data are examined in two passes. 
  # The first pass calculates a difference in pupil size between subsequent data points. If the difference is larger than the value specified in Delta, the data point is marked for removal. # The second pass attempts to identify remaining data points or islands of data points (small runs surrounded by NAs) which remain in the window
  prep_rmart <- clean_artifact(prep_rmblinks, MADWindow = 100, MADConstant = 2,
                                MADPadding = c(200, 200), MahaConstant = 2,
                                Method = "Robust", XandY = TRUE, Second = T, 
                                MaxValueRun = 5, NAsAroundRun = c(2,2),
                                LogFile = log_artifacts_path)
  # plot_compare_app(prep_rmart)
  # The artifcat cleaning algorithm first divides the times series into windows, the size of which is specified in milliseconds using MADWindow. Within each window the median absolute deviation (MAD) of the pupil size data is calculated. This is used to detect which windows contain extreme variability (potentially containing outliers). This is determined based on the value provided in MADConstant, which controls the sensitivity threshold. The higher the constant the more extreme value is needed to trigger cleaning. Next the identified extreme windows have padding added around them using MADPadding (again in milliseconds). Within this padded window, a multidimensional distributional distance (specifically Mahalanobis distance) is calculated. This distance can be calculated using one of two methods: Basic or Robust. The Basic method uses the standard Mahalanobis distance and the Robust uses a robust version of the Mahalanobis distance. The latter is based on Minimum Covariance Determinant (as implemented in the package robustbase), which uses a sampling method for determining multivariate location and scatter. Both the basic and robust calculations are based on multiple variables covarying with pupil size. By default, the calcuation uses the following columns: Pupil, Velocity_Y, and Acceleration_Y.
  
  # The function will inform the user if a particular window is skipped as there are safeguards built in which will skip a given window if: 1) there are not enough data points or 2) there are not enough columns with non-zero data to estimate covariance. To determine whether a given pupil size is extreme, the argument MahaConstant is used to set the sensitivity. The default value of the parameter is 2 (standard deviations). The higher the constant, the more extreme value of the parameter is needed to trigger cleaning. Lastly, this function can optionally perform a second pass (setting Second to TRUE), which is identical to the second pass in clean_blink. This attempts to identify remaining data points or islands of data points (small runs surrounded by NAs) which remain
  # displays the difference in the pupil data before and after carrying out the automatic cleanup
  
  # Linear interpolation and low-pass filtering
  prep_linear <- interpolate_NAs(prep_rmart, Method = "linear", XandY = T, MinData = 2)
  #plot_compare_app(prep_linear)
  prep_filter <- apply_butter(prep_linear, n = 1, W = 0.1, type = "low", plane = "z")
  #plot_compare_app(prep_filter)
  
  # # consider cubic spline as it is smoother 
  # pupil_spline <- interpolate_NAs(pupil_rmart, Method = "spline", XandY = T, MinData = 2)
  # plot_compare_app(datspline) 
  
  # Remove both skipped events and artifacts created by the filterer
  prep_trimmed <- trim_filtered(data = prep_filter, RmSkipped = TRUE, RmEdges = c(75, 75))
  #plot_compare_app(prep_trimmed)
  
  # Convert pupil data from "area" to diameter (mm)
  prep_trimmed <- prep_trimmed %>%
    mutate(Pupil = 8/sqrt(4326)*sqrt(Pupil))
  
  # Check baseline and apply baseline correction
  check_baseline(prep_trimmed, BaselineWindow = c(-baseline_window, 0))
  prep_basecorr <- baseline(prep_trimmed, BaselineWindow = c(-baseline_window, 0), BaselineType = "Subtraction")

  # downsampling
  check_samplingrate(prep_basecorr)
  ds_options(SamplingRate = 500)
  prep_basecorr <- downsample(prep_basecorr, SamplingRate = 500, NewRate = 50)
  
  # Save the preprocessed data
  cat("Saving preprocessed data...\n")
  write_csv(prep_basecorr, paste0(output_path))
  cat(sprintf("Subject %s, task %s, phase %s processing complete!\n\n", subject, task, phase))           
}

```
# read in data
```{r}
dat <- read.delim(paste0(eye_dir, fname))
dat_behav <- read.csv(paste0(proj_dir, subj, '/', behav_fname))

```



# find timing in eye data
```{r}
# cross-check timing against sampling
for (p in c(1:4)) {
  time_start <- which(grepl(phase_name[p], dat$SAMPLE_MESSAGE))
  if (p < 4) {
    time_stop <- which(grepl(phase_name[p+1], dat$SAMPLE_MESSAGE)) - 1
  } else {
    tmp <- which(grepl(phase_name[1], dat$SAMPLE_MESSAGE))
    time_stop <- time_start + tail(phase_dur.adj, n = 1)
  }
  
  if (p == 1) {
    phase_timing.start <- time_start
    phase_timing.stop <- time_stop
  } else {
    phase_timing.start <- cbind(phase_timing.start, time_start)
    phase_timing.stop <- cbind(phase_timing.stop, time_stop)
  }
}

print(paste0('mean fixation dur: ', mean(phase_timing.stop[,1] - phase_timing.start[,1])/samp_rate))
print(paste0('mean cs dur: ', mean(phase_timing.stop[,2] - phase_timing.start[,2])/samp_rate))
print(paste0('mean anticip dur: ', mean(phase_timing.stop[,3] - phase_timing.start[,3])/samp_rate))
print(paste0('mean us dur: ', mean(phase_timing.stop[,4] - phase_timing.start[,4])/samp_rate))

phase_timing.start <- as.data.frame(phase_timing.start)
names(phase_timing.start) <- phase_name

# make sure equal number of timepoints per trial
# add baseline window
phase_timing.match <- phase_timing.start
names(phase_timing.match) <- gsub("onset", "offset", phase_name)

phase_timing.baseline <- phase_timing.start
names(phase_timing.baseline) <- gsub("onset", "baseline", phase_name)

for (k in c(1:4)) {
phase_timing.match[,k] <- phase_timing.match[,k] + phase_dur.adj[k]
phase_timing.baseline[,k] <- phase_timing.baseline[,k] - baseline_dur.adj

}

phase_timing <- cbind(phase_timing.start, phase_timing.match) %>%
  cbind(phase_timing.baseline) %>%
  mutate(us_img = dat[phase_timing.start$fixation_onset,]$us)

```

# subset to relevant eyetracking cols
```{r}
prep_columns <- ppl_prep_data(data = dat, Subject = "RECORDING_SESSION_LABEL")
prep_columns <- ppl_rm_extra_DVcols(prep_columns)
```

# combine w behavior data to get trial numbers
```{r}
timing_behav_merge <- merge(phase_timing, dat_behav %>% select(-c(names(dat_behav)[grepl("onset", names(dat_behav))], 'phase')), by = "us_img") %>%
  mutate(event_num = ((block-1)*60+trial_num)) %>%
  arrange(event_num)
```

# separate by trial phase for analysis
## fixation
```{r}

```

## cs
```{r}

for (e in unique(timing_behav_merge$event_num)) {
  trial_info <- timing_behav_merge %>% filter(event_num==e)
  dat_range <- c(trial_info$cs_baseline:trial_info$cs_offset)
  trial_eye <- prep_columns %>% slice(dat_range) %>%
    cbind(trial_info)
  
  if (e == 1) {
    cs_data = trial_eye
  } else {
    cs_data <- rbind(cs_data, trial_eye)
  }
}

```

## anticipation
```{r}

for (e in unique(timing_behav_merge$event_num)) {
  trial_info <- timing_behav_merge %>% filter(event_num==e)
  dat_range <- c(trial_info$anticipation_baseline:trial_info$anticipation_offset)
  trial_eye <- prep_columns %>% slice(dat_range) %>%
    cbind(trial_info)
  
  if (e == 1) {
    anticip_data = trial_eye
  } else {
    anticip_data <- rbind(anticip_data, trial_eye)
  }
}

```

## us
```{r}

for (e in unique(timing_behav_merge$event_num)) {
  trial_info <- timing_behav_merge %>% filter(event_num==e)
  dat_range <- c(trial_info$us_baseline:trial_info$us_offset)
  trial_eye <- prep_columns %>% slice(dat_range) %>%
    cbind(trial_info)
  
  if (e == 1) {
    us_data = trial_eye
  } else {
    us_data <- rbind(us_data, trial_eye)
  }
}
```

# complete preproc steps for pupil 
```{r}

cs_baseline_window = 1000
task = 'conditioning'
phase = 'cs_onset'
preprocess_eye(subj, task, phase, cs_data, cs_baseline_window, out_dir, log_dir)  

antic_baseline_window = 0
phase = 'anticipation_onset'
preprocess_eye(subj, task, phase, anticip_data, antic_baseline_window, out_dir, log_dir)  

phase = 'us_onset'
preprocess_eye(subj, task, phase, us_data, cs_baseline_window, out_dir, log_dir)  

```

# save unprocessed data for gaze




